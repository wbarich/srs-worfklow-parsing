{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import rich.progress\n",
    "from llm_utils import return_azure_llm\n",
    "import pandas as pd\n",
    "import rich\n",
    "from ipdb import set_trace as st\n",
    "from typing import List, Tuple\n",
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "import rich\n",
    "\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 35, 34, 19]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df = pd.read_csv('annotations.csv')\n",
    "project_ids = annotations_df['ProjectID'].unique().tolist()\n",
    "project_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(\"generated_graphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 35, 34, 19]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['ProjectID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectID</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Start</td>\n",
       "      <td>Access System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Access System</td>\n",
       "      <td>View Menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>View Menu</td>\n",
       "      <td>Exclusive Gateway: Need to log in?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Exclusive Gateway: Need to log in?</td>\n",
       "      <td>User Login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Exclusive Gateway: Need to log in?</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProjectID                           from_node  \\\n",
       "0         20                               Start   \n",
       "1         20                       Access System   \n",
       "2         20                           View Menu   \n",
       "3         20  Exclusive Gateway: Need to log in?   \n",
       "4         20  Exclusive Gateway: Need to log in?   \n",
       "\n",
       "                              to_node  \n",
       "0                       Access System  \n",
       "1                           View Menu  \n",
       "2  Exclusive Gateway: Need to log in?  \n",
       "3                          User Login  \n",
       "4                                 End  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Compare the ground truth workflow against the generated workflows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_node_metrics(ground_truth_nodes, generated_nodes):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    # Convert node lists to sets for easier comparison\n",
    "    ground_truth_set = set(tuple(node) for node in ground_truth_nodes)\n",
    "    generated_set = set(tuple(node) for node in generated_nodes)\n",
    "    \n",
    "    # True Positives: Nodes present in both ground truth and generated set\n",
    "    true_positives = len(ground_truth_set.intersection(generated_set))\n",
    "    \n",
    "    # False Positives: Nodes present in generated set but not in ground truth set\n",
    "    false_positives = len(generated_set - ground_truth_set)\n",
    "    \n",
    "    # False Negatives: Nodes present in ground truth set but not in generated set\n",
    "    false_negatives = len(ground_truth_set - generated_set)\n",
    "    \n",
    "    return true_positives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def dump_cache(cache):\n",
    "    with open('cache.pkl', 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "def retrieve_cache():\n",
    "    try:\n",
    "        with open('cache.pkl', 'rb') as f:\n",
    "            loaded_cache = pickle.load(f)\n",
    "        print(\"Loaded cache from disk\")\n",
    "    except:\n",
    "        print(\"Not loading cache as it does not exist\")\n",
    "        return {}\n",
    "    return loaded_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')\n",
    "\n",
    "embedding_function = AzureOpenAIEmbeddings(          \n",
    "            openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            deployment=os.getenv('EMBEDDING_DEPLOYMENT_NAME'),\n",
    "            model=os.getenv('EMBEDDING_MODEL'),\n",
    "            openai_api_version=os.getenv('AZURE_OPENAI_VERSION'),\n",
    "            azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "            chunk_size=1) \n",
    "\n",
    "embedding_function = embedding_function.embed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cache(query, cache):\n",
    "    if query in cache:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_node_metrics_semantic(ground_truth_nodes, generated_nodes, embed_query, cache):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    # Function to compute semantic similarity between two node descriptions\n",
    "    def compute_similarity(node1, node2, cache):\n",
    "\n",
    "        \n",
    "        if not check_cache(node1, cache):\n",
    "            embedding1 = embed_query(node1)\n",
    "            cache[node1] = embedding1\n",
    "        else:\n",
    "            embedding1 = cache[node1]\n",
    "\n",
    "        if not check_cache(node2, cache):\n",
    "            embedding2 = embed_query(node2)\n",
    "            cache[node2] = embedding2\n",
    "        else:\n",
    "            embedding2 = cache[node2]\n",
    "        \n",
    "        # Compute the cosine similarity between the two embeddings\n",
    "        similarity_score = cosine_similarity([embedding1], [embedding2])[0, 0]\n",
    "        return similarity_score, cache\n",
    "    \n",
    "    # Convert node lists to sets for easier comparison\n",
    "    ground_truth_set = set(tuple(node) for node in ground_truth_nodes)\n",
    "    generated_set = set(tuple(node) for node in generated_nodes)\n",
    "    \n",
    "    # Loop through generated nodes and find matches in ground truth using semantic similarity\n",
    "    for gen_node in generated_set:\n",
    "        match_found = False\n",
    "        for gt_node in ground_truth_set:\n",
    "            similarity_score, cache = compute_similarity(gen_node[0], gt_node[0], cache)\n",
    "            # You can adjust this threshold as needed\n",
    "            if similarity_score > 0.8:  # Example threshold\n",
    "                true_positives += 1\n",
    "                match_found = True\n",
    "                break\n",
    "        if not match_found:\n",
    "            false_positives += 1\n",
    "    \n",
    "    # Count false negatives (ground truth nodes not matched by generated nodes)\n",
    "    for gt_node in ground_truth_set:\n",
    "        match_found = False\n",
    "        for gen_node in generated_set:\n",
    "            similarity_score, cache = compute_similarity(gen_node[0], gt_node[0], cache)\n",
    "            if similarity_score > 0.8:  # Example threshold\n",
    "                match_found = True\n",
    "                break\n",
    "        if not match_found:\n",
    "            false_negatives += 1\n",
    "    \n",
    "    return true_positives, false_positives, false_negatives, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache from disk\n"
     ]
    }
   ],
   "source": [
    "columns = ['ProjectID', 'TP', 'FP', 'FN', 'TP with Semantic', 'FP with Semantic', 'FN with Semantic']\n",
    "metrics_df = pd.DataFrame(columns=columns)\n",
    "cache = retrieve_cache()\n",
    "\n",
    "for project_id in project_ids:\n",
    "\n",
    "    results = {'ProjectID': project_id, 'TP': 0, 'FP': 0, 'FN': 0, 'TP with Semantic': 0, 'FP with Semantic': 0, 'FN with Semantic': 0}\n",
    "\n",
    "    #retrieve the ground truth and generated nodes to compare against each other\n",
    "    generated_nodes = output_df.loc[output_df['ProjectID']==project_id, ['from_node', 'to_node']].values.tolist()\n",
    "    ground_truth_nodes = annotations_df.loc[annotations_df['ProjectID']==project_id, ['Step', 'Next Step']].values.tolist()\n",
    "\n",
    "    #calculate TP, FP, FN for each project WITHOUT semantic comparison\n",
    "    results['TP'], results['FP'], results['FN'] = calculate_node_metrics(ground_truth_nodes, generated_nodes)\n",
    "\n",
    "    #calculate TP, FP, FN for each project WITH semantic comparison\n",
    "    results['TP with Semantic'], results['FP with Semantic'], results['FN with Semantic'], cache = calculate_node_metrics_semantic(ground_truth_nodes, generated_nodes, embedding_function, cache)\n",
    "\n",
    "    #calculate the edge scores for each project WITHOUT semantic comparison\n",
    "\n",
    "    #calculate the edge scores for each project WITH semantic comparison\n",
    "\n",
    "    #append all data to metric df\n",
    "    metrics_df = pd.concat((metrics_df, pd.DataFrame([results])), axis = 0)\n",
    "\n",
    "    dump_cache(cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectID</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP with Semantic</th>\n",
       "      <th>FP with Semantic</th>\n",
       "      <th>FN with Semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProjectID  TP  FP  FN TP with Semantic FP with Semantic FN with Semantic\n",
       "0        20  30   0   0               30                0                0\n",
       "0        35   8   7   8               15                0                1\n",
       "0        34   1  22  20               22                1                0\n",
       "0        19   3   6  10                8                1                2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
